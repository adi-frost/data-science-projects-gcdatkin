{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c2c35b-b971-4adc-b7c5-e748f5edf3f2",
   "metadata": {},
   "source": [
    "## Age Prediction From Facial Images (CNN Regression)\n",
    "\n",
    "Given *images of people ages 20-25, let's try to predict the **age** of the person in a given image. \n",
    "\n",
    "We will use a TensorFlow/Keras CNN to make our predictions. \n",
    "\n",
    "Data source: https://www.kaggle.com/datasets/mariafrenti/age-prediction?resource=download-directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a13815-3d98-42f3-a5b0-ed826ddd533e",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b81dc11-0e40-4b56-aefa-4c063d3ba8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 10:32:29.237541: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b15094-20aa-43de-b2bc-4a0d34aaa02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path(\"archive/20-50/20-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98ac0c-0bd6-423a-a52c-4b8cbaa7cd28",
   "metadata": {},
   "source": [
    "### Create File DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff6c43ae-53f5-496e-b290-4e4894e86f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        archive/20-50/20-50/train/50/101453.jpg\n",
       "1        archive/20-50/20-50/train/50/124365.jpg\n",
       "2        archive/20-50/20-50/train/50/161895.jpg\n",
       "3        archive/20-50/20-50/train/50/147106.jpg\n",
       "4        archive/20-50/20-50/train/50/120820.jpg\n",
       "                          ...                   \n",
       "40435      archive/20-50/20-50/test/30/43585.jpg\n",
       "40436      archive/20-50/20-50/test/30/40997.jpg\n",
       "40437      archive/20-50/20-50/test/30/42987.jpg\n",
       "40438      archive/20-50/20-50/test/30/41229.jpg\n",
       "40439      archive/20-50/20-50/test/30/41971.jpg\n",
       "Name: Filepath, Length: 40440, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths = pd.Series(list(image_dir.glob(r'**/*.jpg')), name='Filepath').astype(str)\n",
    "filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9f525d-2667-4595-9784-089ce0ed5092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split(os.path.split(filepaths.values[0])[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e052e38-312f-43bf-97d0-e55166de7ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        50\n",
       "1        50\n",
       "2        50\n",
       "3        50\n",
       "4        50\n",
       "         ..\n",
       "40435    30\n",
       "40436    30\n",
       "40437    30\n",
       "40438    30\n",
       "40439    30\n",
       "Name: Age, Length: 40440, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = pd.Series(filepaths.apply(lambda x: os.path.split(os.path.split(x)[0])[1]), name='Age').astype(int)\n",
    "ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e23f756-f8fc-4811-85eb-33a658d4cad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>archive/20-50/20-50/train/36/157214.jpg</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>archive/20-50/20-50/train/22/151160.jpg</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>archive/20-50/20-50/train/20/142010.jpg</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>archive/20-50/20-50/train/41/170361.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>archive/20-50/20-50/train/35/159922.jpg</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40435</th>\n",
       "      <td>archive/20-50/20-50/train/34/147485.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40436</th>\n",
       "      <td>archive/20-50/20-50/train/30/174724.jpg</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40437</th>\n",
       "      <td>archive/20-50/20-50/train/40/172530.jpg</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40438</th>\n",
       "      <td>archive/20-50/20-50/train/44/170297.jpg</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40439</th>\n",
       "      <td>archive/20-50/20-50/train/30/165058.jpg</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40440 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Filepath  Age\n",
       "0      archive/20-50/20-50/train/36/157214.jpg   36\n",
       "1      archive/20-50/20-50/train/22/151160.jpg   22\n",
       "2      archive/20-50/20-50/train/20/142010.jpg   20\n",
       "3      archive/20-50/20-50/train/41/170361.jpg   41\n",
       "4      archive/20-50/20-50/train/35/159922.jpg   35\n",
       "...                                        ...  ...\n",
       "40435  archive/20-50/20-50/train/34/147485.jpg   34\n",
       "40436  archive/20-50/20-50/train/30/174724.jpg   30\n",
       "40437  archive/20-50/20-50/train/40/172530.jpg   40\n",
       "40438  archive/20-50/20-50/train/44/170297.jpg   44\n",
       "40439  archive/20-50/20-50/train/30/165058.jpg   30\n",
       "\n",
       "[40440 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = pd.concat([filepaths, ages], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dfc2703-5949-42de-aa5d-be86fa8eebe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>archive/20-50/20-50/train/30/178764.jpg</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>archive/20-50/20-50/train/28/146677.jpg</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>archive/20-50/20-50/train/36/153656.jpg</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>archive/20-50/20-50/train/49/161853.jpg</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>archive/20-50/20-50/train/23/162384.jpg</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>archive/20-50/20-50/train/28/148801.jpg</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>archive/20-50/20-50/train/39/154481.jpg</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>archive/20-50/20-50/train/35/175360.jpg</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>archive/20-50/20-50/train/42/154401.jpg</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>archive/20-50/20-50/train/22/168478.jpg</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Filepath  Age\n",
       "0     archive/20-50/20-50/train/30/178764.jpg   30\n",
       "1     archive/20-50/20-50/train/28/146677.jpg   28\n",
       "2     archive/20-50/20-50/train/36/153656.jpg   36\n",
       "3     archive/20-50/20-50/train/49/161853.jpg   49\n",
       "4     archive/20-50/20-50/train/23/162384.jpg   23\n",
       "...                                       ...  ...\n",
       "4995  archive/20-50/20-50/train/28/148801.jpg   28\n",
       "4996  archive/20-50/20-50/train/39/154481.jpg   39\n",
       "4997  archive/20-50/20-50/train/35/175360.jpg   35\n",
       "4998  archive/20-50/20-50/train/42/154401.jpg   42\n",
       "4999  archive/20-50/20-50/train/22/168478.jpg   22\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's only use 5000 images to speed up training time\n",
    "image_df = images.sample(5000, random_state=1).reset_index(drop=True)\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c346283b-b1b9-44a3-82d4-93aae94b8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d45b9e6-af0b-477c-8cb5-8e3d70f301fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 1500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a47130b-ef36-409f-b7c0-10a4755eea19",
   "metadata": {},
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d63d6c8-3de3-4f65-9d39-51ef55af3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f592a944-f63e-4be2-9be1-1e2eedb99839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2800 validated image filenames.\n",
      "Found 700 validated image filenames.\n",
      "Found 1500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_gen.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'Filepath',\n",
    "    y_col = 'Age',\n",
    "    target_size = (120, 120),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'raw',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed = 42,\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "val_images = train_gen.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'Filepath',\n",
    "    y_col = 'Age',\n",
    "    target_size = (120, 120),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'raw',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed = 42,\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "test_images = test_gen.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col = 'Filepath',\n",
    "    y_col = 'Age',\n",
    "    target_size = (120, 120),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'raw',\n",
    "    batch_size = 32,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edefef3-496c-461f-bb73-253ace996d00",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6105bb8-e3e7-4da7-8943-c48f2213d51a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 13:03:53.414345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - ETA: 0s - loss: 540.9442   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 13:04:10.209971: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 19s 199ms/step - loss: 540.9442 - val_loss: 141.6603\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 17s 189ms/step - loss: 138.4384 - val_loss: 104.8984\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 93.8414 - val_loss: 80.2480\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 16s 177ms/step - loss: 83.9261 - val_loss: 78.7269\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 16s 176ms/step - loss: 83.2007 - val_loss: 78.7868\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 82.9801 - val_loss: 79.5208\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 83.7188 - val_loss: 82.2812\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 83.8393 - val_loss: 79.9814\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 83.1263 - val_loss: 78.8446\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(120, 120, 3))\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'mse'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data = val_images,\n",
    "    epochs=100,\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = 5,\n",
    "            restore_best_weights = True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4ec7cd6-d3fd-4de4-8424-cf655f11675f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 120, 120, 3) dtype=float32 (created by layer 'input_3')>,\n",
       " <KerasTensor: shape=(None, 118, 118, 16) dtype=float32 (created by layer 'conv2d_3')>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bee7da2-82ca-4c2a-ac46-1b6b0165d59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 28, 28, 32) dtype=float32 (created by layer 'max_pooling2d_3')>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e96702b-cfa7-442b-b2c3-107d311bc25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25088) dtype=float32 (created by layer 'flatten')>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Flatten()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c3774-62d7-4018-a39b-bf985eaad3ab",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbac2624-3940-4f09-9f5a-f891caa14e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/47 [..............................] - ETA: 8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 13:22:01.988122: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 5s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_ages = np.squeeze(model.predict(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1f3585f-2ed3-4670-824e-428cbc0be2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 13:25:03.183849: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 8.91531\n",
      "Test R2 Score: 0.00358\n"
     ]
    }
   ],
   "source": [
    "true_ages = test_images.labels\n",
    "rmse = np.sqrt(model.evaluate(test_images, verbose=0))\n",
    "print(\"Test RMSE: {:.5f}\".format(rmse))\n",
    "\n",
    "r2 = r2_score(true_ages, predicted_ages)\n",
    "print(\"Test R2 Score: {:.5f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b73a591-10c6-4d59-9c4f-1783f45aa3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.660666666666664"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(true_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab5fdd3c-2969-4e11-8985-7163d802e2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.93130372466541"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((true_ages - np.mean(true_ages))**2)/len(true_ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e88c6-1a34-475d-a042-084665c9f830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2039bc-5bed-4741-851a-4c5e364cd7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2534e-d3eb-434d-b8dd-8e26058d772a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178bdc2-bd3b-4753-8b72-e750bed65b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
